{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterbrezovcsik/miniconda3/envs/face_recognition/lib/python3.12/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/peterbrezovcsik/miniconda3/envs/face_recognition/lib/python3.12/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <367D4265-B20F-34BD-94EB-4F3EE47C385B> /Users/peterbrezovcsik/miniconda3/envs/face_recognition/lib/python3.12/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/peterbrezovcsik/miniconda3/envs/face_recognition/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/peterbrezovcsik/miniconda3/envs/face_recognition/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/peterbrezovcsik/miniconda3/envs/face_recognition/lib/python3.12/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/peterbrezovcsik/miniconda3/envs/face_recognition/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "from azure.ai.ml.entities import Workspace, Environment\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/136916772708828886', creation_time=1739206421607, experiment_id='136916772708828886', last_update_time=1739206421607, lifecycle_stage='active', name='array_demo', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('http://127.0.0.1:8080')\n",
    "mlflow.set_experiment('array_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.13333</td>\n",
       "      <td>0.43038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.53333</td>\n",
       "      <td>0.03038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1        2\n",
       "0  0.13333  0.43038\n",
       "1  0.53333  0.03038"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = np.array([0.13333, 0.43038])\n",
    "step = 0\n",
    "df = pd.DataFrame(columns=['1', '2'])\n",
    "df.loc[step] = metrics\n",
    "df.loc[step+1] = np.array([0.53333, 0.03038])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsLogger():\n",
    "    def __init__(self, columns):\n",
    "        self.df_f1 = pd.DataFrame(columns=columns)\n",
    "        self.df_rec = pd.DataFrame(columns=columns)\n",
    "        self.df_prec = pd.DataFrame(columns=columns)\n",
    "        self.df_acc = pd.DataFrame(columns=columns)\n",
    "        \n",
    "    \n",
    "    def log_metrics(self, stage, metrics, step):\n",
    "        \n",
    "        mlflow.log_metric(f\"Loss_{stage}\", f\"{metrics['loss']:2f}\", step=step)\n",
    "        mlflow.log_metric(f\"Hamming_loss_{stage}\", f\"{metrics['hamming_loss']:2f}\", step=step)\n",
    "        mlflow.log_metric(f'Subset_Accuracy_{stage}', metrics['averaged_example_based_accuracy'], step=step)\n",
    "\n",
    "        mlflow.log_metric(f'F1_Score_Micro_{stage}', metrics['f1_score']['micro_averaged'], step=step)\n",
    "        mlflow.log_metric(f'F1_Score_Macro_{stage}', metrics['f1_core']['micro_averaged'], step=step)\n",
    "        mlflow.log_metric(f'F1_Score_Sample_{stage}', metrics['f1_core']['sample_average'], step=step)\n",
    "        mlflow.log_metric(f'F1_Score_Weighted_{stage}', metrics['f1_core']['weighted_averaged'], step=step)\n",
    "        if stage == 'eval':\n",
    "            self.df_f1.loc[step] = metrics['f1_score']['per_label']\n",
    "            self.df_rec.loc[step] = metrics['recall']['per_label']\n",
    "            self.df_prec.loc[step] = metrics['precision']['per_label']\n",
    "            #self.df_acc.loc[step] = metrics['accuracy']['per_label']\n",
    "    \n",
    "    def save_artifact(self, path):\n",
    "        mlflow.log_table(self.df_f1, 'f1_score_per_label.csv')\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Image size: {training_data[0][0].shape}\")\n",
    "print(f\"Size of training dataset: {len(training_data)}\")\n",
    "print(f\"Size of test dataset: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(10),  # 10 classes in total.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    \"\"\"Train the model on a single pass of the dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataloader: an instance of `torch.utils.data.DataLoader`, containing the training data.\n",
    "        model: an instance of `torch.nn.Module`, the model to be trained.\n",
    "        loss_fn: a callable, the loss function.\n",
    "        metrics_fn: a callable, the metrics function.\n",
    "        optimizer: an instance of `torch.optim.Optimizer`, the optimizer used for training.\n",
    "        epoch: an integer, the current epoch number.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        #accuracy = metrics_fn(pred, y)\n",
    "\n",
    "        # Backpropagation.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            step = batch // 100 * (epoch + 1)\n",
    "            mlflow.log_metric(\"loss\", f\"{loss:2f}\", step=step)\n",
    "            #mlflow.log_metric(\"accuracy\", f\"{accuracy:2f}\", step=step)\n",
    "            print(f\"loss: {loss:2f} accuracy: NA [{current} / {len(dataloader)}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, epoch):\n",
    "    \"\"\"Evaluate the model on a single pass of the dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataloader: an instance of `torch.utils.data.DataLoader`, containing the eval data.\n",
    "        model: an instance of `torch.nn.Module`, the model to be trained.\n",
    "        loss_fn: a callable, the loss function.\n",
    "        metrics_fn: a callable, the metrics function.\n",
    "        epoch: an integer, the current epoch number.\n",
    "    \"\"\"\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "            eval_accuracy += metrics_fn(pred, y)\n",
    "\n",
    "    eval_loss /= num_batches\n",
    "    #eval_accuracy /= num_batches\n",
    "    mlflow.log_metric(\"eval_loss\", f\"{eval_loss:2f}\", step=epoch)\n",
    "    #mlflow.log_metric(\"eval_accuracy\", f\"{eval_accuracy:2f}\", step=epoch)\n",
    "\n",
    "    print(f\"Eval metrics: \\nAccuracy: NA, Avg loss: {eval_loss:2f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#metric_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "model = ImageClassifier().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='f_mnist_test') as run:\n",
    "    params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 64,\n",
    "        \"loss_function\": loss_fn.__class__.__name__,\n",
    "        #\"metric_function\": metric_fn.__class__.__name__,\n",
    "        \"optimizer\": \"SGD\",\n",
    "    }\n",
    "    # Log training parameters.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer, epoch=t)\n",
    "        evaluate(test_dataloader, model, loss_fn, epoch=t)\n",
    "\n",
    "    # Save the trained model to MLflow.\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = f\"runs:/{run.info.run_id}/model\"\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = loaded_model.predict(training_data[2][0][None, :].numpy())\n",
    "nn.Softmax(dim=1)(torch.tensor(outputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
